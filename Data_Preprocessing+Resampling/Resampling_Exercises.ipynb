{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Methods\n",
    "\n",
    "The goal of predictive modeling is to create models that make good predictions on new data. We\n",
    "don't have access to this new data at the time of training, so we must use statistical methods to estimate the performance of a model on new data. This class of methods are called resampling methods, as they resampling your available training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "We will now derive the probability that a given observation is part\n",
    "of a bootstrap sample. Suppose that we obtain a bootstrap sample\n",
    "from a set of n observations.\n",
    "\n",
    "(a) What is the probability that the first bootstrap observation is\n",
    "not the jth observation from the original sample? Justify your\n",
    "answer.\n",
    "\n",
    "(b) What is the probability that the second bootstrap observation\n",
    "is not the jth observation from the original sample?\n",
    "\n",
    "(c) Argue that the probability that the jth observation is not in the\n",
    "bootstrap sample is $(1 âˆ’ 1/n) ^ n$.\n",
    "\n",
    "(d) When n = 5, what is the probability that the jth observation is\n",
    "in the bootstrap sample?\n",
    "\n",
    "(e) When n = 100, what is the probability that the jth observation\n",
    "is in the bootstrap sample\n",
    "\n",
    "(f)When n = 10,000, what is the probability that the jth observation\n",
    "is in the bootstrap sample?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "a) (n-1)/n \n",
    "\n",
    "bootstrap sampling is random, so there is only a 1/n chance of the observation being any paticular sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) (n-1)/n\n",
    "\n",
    "bootstrapping uses replacement, so the chance is the same with the second observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) If the chance that the jth observation is not in the bootstrap sample is (1 - 1/n), it will be (1-1/n)^n when sampled n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d) 0.6723199999999999\n"
     ]
    }
   ],
   "source": [
    "print(f\"d) {1-(1-1/5)**5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e) 0.6339676587267709\n"
     ]
    }
   ],
   "source": [
    "print(f\"e) {1-(1-1/100)**100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f) 0.6321223982317534\n"
     ]
    }
   ],
   "source": [
    "print(f\"f) {1-(1-1/100000)**100000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "We now review k-fold cross-validation.\n",
    "\n",
    "(a) Explain how k-fold cross-validation is implemented.\n",
    "\n",
    "(b) What are the advantages and disadvantages of k-fold crossvalidation\n",
    "relative to:\n",
    "    \n",
    "    i. The validation set approach?\n",
    "    \n",
    "    ii. LOOCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "a) Randomly sampling a subset of the data for testing purposes and using the rest for training, then soing this n times until the whole dataset has been used for testing the model. Then averaging those results to produce a model of the dataset as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bi) advantage: nullifies the risk of the training split not being representative of the dataset as a whole (lowers error)\n",
    "\n",
    "bii) advantage: very low bias due to using almost the entirely dataset for training\n",
    "\n",
    "disadvantage: as the training sets are all nearly identical, they are naturally highly correlated with each other. Also, since the training set is all the data - 1 sample, the computational requirements are high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Suppose that we use some statistical learning method to make a prediction\n",
    "for the response Y for a particular value of the predictor X.\n",
    "Carefully describe how we might estimate the standard deviation of\n",
    "our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise - Credit Card Default Data Set\n",
    "\n",
    "We previously used logistic regression to predict the probability of `default` using `income` and `balance` on the `Default` data set. We will now estimate the test error of this logistic regression model using the validation set approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** - Fit a logistic regression model that uses `income` and `balance` to predict `default`. Compare the error of the scikit-learn and statsmodel implementations without the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default student      balance        income\n",
       "0        0      No   729.526495  44361.625074\n",
       "1        0     Yes   817.180407  12106.134700\n",
       "2        0      No  1073.549164  31767.138947\n",
       "3        0      No   529.250605  35704.493935\n",
       "4        0      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default = pd.read_csv(\"default.csv\")\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am confused here as to why you would only use the default == yes dataset for fitting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>default</td>     <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 23 Jul 2017</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:29:52</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                default   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sun, 23 Jul 2017   Pseudo R-squ.:                  0.4594\n",
       "Time:                        15:29:52   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "                                        LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
       "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
       "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statsmodels\n",
    "results = smf.logit('default ~ balance + income', data=default).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -1.94164125e-06]), array([[ 0.00040756, -0.00012588]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn\n",
    "X = default[['balance', 'income']]\n",
    "y = default.default\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "lr.intercept_, lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96640000000000004"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lr.predict(X) == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97370000000000001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((results.predict(X) > 0.5) == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** - Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "\n",
    "1. Split the sample set into a training set and a validation set.\n",
    "2. Fit a multiple logistic regression model using only the training observations.\n",
    "3. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the `default` category if the posterior probability is greater than 0.5.\n",
    "4. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.\n",
    "5. Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.\n",
    "6. Now consider a logistic regression model that predicts the probability of `default` using `income`, `balance`, and a dummy variable for `student`. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for `student` leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9667\n",
       "1     333\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 97.12%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "lr = lr = LogisticRegression(C=100000, tol=0.0000001)\n",
    "lr.fit(X_train, y_train)\n",
    "print(f\"Prediction Accuracy: {round(((lr.predict(X_test) == y_test).mean()) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 2.88%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Error rate: {round((1 - (lr.predict(X_test) == y_test).mean()) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 97.48%\n",
      "Error rate: 2.52%\n",
      "Prediction Accuracy: 97.44%\n",
      "Error rate: 2.56%\n",
      "Prediction Accuracy: 97.88%\n",
      "Error rate: 2.12%\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=i)\n",
    "    lr = lr = LogisticRegression(C=100000, tol=0.0000001)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(f\"Prediction Accuracy: {round(((lr.predict(X_test) == y_test).mean()) * 100, 2)}%\")\n",
    "    print(f\"Error rate: {round((1 - (lr.predict(X_test) == y_test).mean()) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty similar results for different testing/training splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default['student'] = np.where(default['student'] == \"Yes\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 97.44%\n",
      "Error rate: 2.56%\n",
      "Prediction Accuracy: 97.52%\n",
      "Error rate: 2.48%\n",
      "Prediction Accuracy: 97.84%\n",
      "Error rate: 2.16%\n"
     ]
    }
   ],
   "source": [
    "X = default[['balance', 'income', 'student']]\n",
    "y = default.default\n",
    "for i in range(1,4):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=i)\n",
    "    lr = lr = LogisticRegression(C=100000, tol=0.0000001)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(f\"Prediction Accuracy: {round(((lr.predict(X_test) == y_test).mean()) * 100, 2)}%\")\n",
    "    print(f\"Error rate: {round((1 - (lr.predict(X_test) == y_test).mean()) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much the same results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** - Compute estimates for the standard errors of the `income` and `balance` logistic regression coefficients by using the bootrap and logistic regression functions.\n",
    "\n",
    "1. Use the summary() method on the logistic regression statsmodel instance.\n",
    "2. Implement your own bootstrap method and run the model 100 times\n",
    "3. Comment on the estimated standard errors obtained using statsmodels and your bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>default</td>     <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 23 Jul 2017</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:23:23</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                default   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sun, 23 Jul 2017   Pseudo R-squ.:                  0.4594\n",
       "Time:                        16:23:23   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "                                        LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
       "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
       "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = smf.logit('default ~ income + balance', data=default).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Intercept   -11.540468\n",
       " income        0.000021\n",
       " balance       0.005647\n",
       " dtype: float64, Intercept    0.434772\n",
       " income       0.000005\n",
       " balance      0.000227\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.params, results.bse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_params = pd.DataFrame(columns=['Intercept', 'income', 'balance'])\n",
    "\n",
    "for i in range(100):\n",
    "    sample = default.sample(len(default), replace=True)\n",
    "    row = smf.logit('default ~ income + balance', data=sample).fit(disp=False)\n",
    "    df_params = df_params.append(row.params, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Intercept   -11.575390\n",
       " income        0.000021\n",
       " balance       0.005665\n",
       " dtype: float64, Intercept    0.425461\n",
       " income       0.000004\n",
       " balance      0.000231\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_params.mean(), df_params.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 -  Stock Market Data\n",
    "\n",
    "**Task** - We will compute the LOOCV error for a simple logistic regression model on the `SMarket` data set.  \n",
    "\n",
    "1. Read in the stock market data set\n",
    "2. Fit a logistic regression model that predicts `Direction` using `Lag1` and `Lag2`.\n",
    "3. Fit a logistic regression model that predicts `Direction` using `Lag1` and `Lag2` using all but the first observation.\n",
    "4. Use the model from (3) to predict the direction of the first observation. You can do this by predicting that the first observation will go up if $P(\\mbox{direction = Up} | Lag1,Lag2 ) > 0.5$. Was this observation correctly classified?\n",
    "5. Write a loop from `i=1` to `i=n`, where n is the number of observations in the data set, that performs each of the following steps:\n",
    "    - Fit a logistic regression model using all but the ith observation to predict `Direction` using `Lag1` and `Lag2`.\n",
    "    - Compute the posterior probability of the market moving up for the ith observation.\n",
    "    - Use the posterior probability for the ith observation in order to predict whether or not the market moves up.\n",
    "    - Determine whether or not an error was made in predicting the direction for the ith observation. If an error was made, then indicate this as a 1, and otherwise indicate it as a 0.\n",
    "6. Take the average of the n numbers obtained in (5) in order to obtain the LOOCV estimate for the test error. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "0  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "1  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "3  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "4  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.read_csv('Smarket.csv', usecols=range(1,10))\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocks['Direction'] = np.where(stocks['Direction'] == 'Up', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691361\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Direction</td>    <th>  No. Observations:  </th>  <td>  1250</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1247</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 23 Jul 2017</td> <th>  Pseudo R-squ.:     </th> <td>0.001601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:46:14</td>     <th>  Log-Likelihood:    </th> <td> -864.20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -865.59</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.2502</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0742</td> <td>    0.057</td> <td>    1.310</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>   -0.0715</td> <td>    0.050</td> <td>   -1.427</td> <td> 0.153</td> <td>   -0.170</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>   -0.0445</td> <td>    0.050</td> <td>   -0.890</td> <td> 0.374</td> <td>   -0.142</td> <td>    0.054</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              Direction   No. Observations:                 1250\n",
       "Model:                          Logit   Df Residuals:                     1247\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sun, 23 Jul 2017   Pseudo R-squ.:                0.001601\n",
       "Time:                        16:46:14   Log-Likelihood:                -864.20\n",
       "converged:                       True   LL-Null:                       -865.59\n",
       "                                        LLR p-value:                    0.2502\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0742      0.057      1.310      0.190      -0.037       0.185\n",
       "Lag1          -0.0715      0.050     -1.427      0.153      -0.170       0.027\n",
       "Lag2          -0.0445      0.050     -0.890      0.374      -0.142       0.054\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = smf.logit('Direction ~ Lag1 + Lag2', data=stocks).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82720000000000005"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results.predict(stocks[['Lag1', 'Lag2']]) > 0.5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_loocv = stocks.iloc[1:]\n",
    "first_obs = stocks.iloc[:1][['Lag1', 'Lag2', 'Direction']] #[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691382\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Direction</td>    <th>  No. Observations:  </th>  <td>  1249</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1246</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 23 Jul 2017</td> <th>  Pseudo R-squ.:     </th> <td>0.001612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:48:42</td>     <th>  Log-Likelihood:    </th> <td> -863.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -864.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.2480</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0727</td> <td>    0.057</td> <td>    1.282</td> <td> 0.200</td> <td>   -0.038</td> <td>    0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>   -0.0720</td> <td>    0.050</td> <td>   -1.436</td> <td> 0.151</td> <td>   -0.170</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>   -0.0443</td> <td>    0.050</td> <td>   -0.885</td> <td> 0.376</td> <td>   -0.142</td> <td>    0.054</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              Direction   No. Observations:                 1249\n",
       "Model:                          Logit   Df Residuals:                     1246\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sun, 23 Jul 2017   Pseudo R-squ.:                0.001612\n",
       "Time:                        16:48:42   Log-Likelihood:                -863.54\n",
       "converged:                       True   LL-Null:                       -864.93\n",
       "                                        LLR p-value:                    0.2480\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0727      0.057      1.282      0.200      -0.038       0.184\n",
       "Lag1          -0.0720      0.050     -1.436      0.151      -0.170       0.026\n",
       "Lag2          -0.0443      0.050     -0.885      0.376      -0.142       0.054\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = smf.logit('Direction ~ Lag1 + Lag2', data=stocks_loocv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82240000000000002"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results.predict(stocks[['Lag1', 'Lag2']]) > 0.5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1.0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_obs.Direction[0], (results.predict(first_obs) > 0.5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay successful prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV Error: 0.484\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(len(stocks)-1):\n",
    "    lr = LogisticRegression(C=100000, tol=0.000001)\n",
    "    X = stocks[stocks.index != i][['Lag1', 'Lag2']]\n",
    "    y = stocks[stocks.index != i]['Direction']\n",
    "    lr.fit(X,y)\n",
    "    if stocks.iloc[i]['Direction'] != lr.predict(stocks.iloc[i][['Lag1', 'Lag2']].values.reshape(1,-1))[0]:\n",
    "        error += 1\n",
    "print(f\"LOOCV Error: {error/len(stocks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48.4% is an extremely high error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6 - Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x = np.random.randn(100)\n",
    "e = np.random.randn(100)\n",
    "y = x - 2*x**2 + e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** - We will now perform cross-validation on a simulated data set.\n",
    "\n",
    "1. Create a scatterplot of X against Y. Comment on what you find.\n",
    "2. Compute the LOOCV errors that result from fitting the following four models using least squares: Linear, Quadratic, Cubic and Quartic.\n",
    "3. Repeat (2) using another random seed, and report your results. Are your results the same as what you got in (2)? Why?\n",
    "4. Which of the models in (3) had the smallest LOOCV error? Is this what you expected? Explain your answer.\n",
    "5. Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in (2) using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a0d3198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation seems to be parabolic (quadratic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df = pd.DataFrame(np.array([np.ones(len(x)), x, x**2, x**3, x**4, y]).T,\n",
    "                     columns=['b0', 'linear', 'quadratic', 'cubic', 'quartic', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV linear Error: 11.610208269693622\n",
      "LOOCV quadratic Error: 1.2652839413336208\n",
      "LOOCV cubic Error: 1.2820418215169613\n",
      "LOOCV quartic Error: 1.3165915804276818\n"
     ]
    }
   ],
   "source": [
    "X = fit_df.iloc[:, :5]\n",
    "y = fit_df['y']\n",
    "lr = LinearRegression()\n",
    "\n",
    "for col in range(4):\n",
    "    error = 0 \n",
    "    for row in range(len(x)):\n",
    "        leave_out = ~X.index.isin([row])\n",
    "        lr.fit(X.iloc[leave_out, :col+2], y[leave_out])\n",
    "        error += (lr.predict(X.iloc[row, :col+2].values.reshape(1,-1)) - y[row]) **2\n",
    "    print(f\"LOOCV {fit_df.columns[col+1]} Error: {error[0]/100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV linear Error: 11.610208269693622\n",
      "LOOCV linear coefficient(s): 1.8693293534124558\n",
      "LOOCV quadratic Error: 1.2652839413336208\n",
      "LOOCV quadratic coefficient(s): -2.123853491596635\n",
      "LOOCV cubic Error: 1.2820418215169613\n",
      "LOOCV cubic coefficient(s): -0.01646547927193165\n",
      "LOOCV quartic Error: 1.3165915804276818\n",
      "LOOCV quartic coefficient(s): -0.004309664505434567\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "x = np.random.randn(100)\n",
    "e = np.random.randn(100)\n",
    "y = x - 2*x**2 + e\n",
    "\n",
    "fit_df = pd.DataFrame(np.array([np.ones(len(x)), x, x**2, x**3, x**4, y]).T,\n",
    "                     columns=['b0', 'linear', 'quadratic', 'cubic', 'quartic', 'y'])\n",
    "\n",
    "X = fit_df.iloc[:, :5]\n",
    "y = fit_df['y']\n",
    "lr = LinearRegression()\n",
    "\n",
    "for col in range(4):\n",
    "    error = 0 \n",
    "    column = fit_df.columns[col+1]\n",
    "    for row in range(len(x)):\n",
    "        leave_out = ~X.index.isin([row])\n",
    "        lr.fit(X.iloc[leave_out, :col+2], y[leave_out])\n",
    "        error += (lr.predict(X.iloc[row, :col+2].values.reshape(1,-1)) - y[row]) **2\n",
    "    print(f\"LOOCV {column} Error: {error[0]/100}\")\n",
    "    print(f\"LOOCV {column} coefficient(s): {LinearRegression().fit(fit_df.iloc[:,:col+2], fit_df['y']).coef_[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rates are pretty similar. Quadratic has the lowest error (by a little bit), which was expected from the scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.512563\n",
      "         Iterations 5\n",
      "\n",
      "\n",
      "LOOCV linear coefficient(s): 2.1868819244326114\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.437388\n",
      "         Iterations 5\n",
      "\n",
      "\n",
      "LOOCV quadratic coefficient(s): -3.5362802225441534\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.437487\n",
      "         Iterations 6\n",
      "\n",
      "\n",
      "LOOCV cubic coefficient(s): 0.5233705062983773\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.437559\n",
      "         Iterations 6\n",
      "\n",
      "\n",
      "LOOCV quartic coefficient(s): -0.7977187985821226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "scaled_df = pd.DataFrame(mms.fit_transform(fit_df),\n",
    "                     columns=['b0', 'linear', 'quadratic', 'cubic', 'quartic', 'y'])\n",
    "for col in range(4):\n",
    "    column = scaled_df.columns[col+1]\n",
    "    formula = 'y ~ ' + ' + '.join(scaled_df.columns[1:col+2])\n",
    "    results = smf.logit(formula, data=scaled_df).fit()\n",
    "    print('\\n')\n",
    "    print(f\"LOOCV {column} coefficient(s): {results.params[-1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients are similar, but not exactly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7 - Boston Housing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** - We will now consider the `Boston` housing data set that we have used previously.\n",
    "\n",
    "1. Based on this data set, provide an estimate for the population mean of `medv`. Call this estimate $\\hat{\\mu}$.\n",
    "2. Provide an estimate of the standard error of $\\hat{\\mu}$. Interpret this result.\n",
    "3. Now estimate the standard error of $\\hat{\\mu}$ using the bootstrap. How does this compare to your answer from (2)?\n",
    "4. Based on your bootstrap estimate from (3), provide a 95% confidence interval for the mean of `medv`. Compare it to the results obtained from a t.test on `medv`.\n",
    "5. Based on this data set, provide an estimate, $\\hat{\\mu}$ med, for the median value of `medv` in the population.\n",
    "6. We now would like to estimate the standard error of $\\hat{\\mu}$ med. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings.\n",
    "7. Based on this data set, provide an estimate for the tenth percentile of `medv` in Boston suburbs. Call this quantity $\\hat{\\mu}$ 0.1.\n",
    "8. Use the bootstrap to estimate the standard error of $\\hat{\\mu}$ 0.1. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
