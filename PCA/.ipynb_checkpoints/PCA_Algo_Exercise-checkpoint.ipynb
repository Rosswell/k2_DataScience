{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "The sheer size of data in the modern age is not only a challenge for computer hardware but also a main bottleneck for the performance of many machine learning algorithms. The main goal of a PCA analysis is to identify patterns in data; PCA aims to detect the correlation between variables. If a strong correlation between variables exists, the attempt to reduce the dimensionality only makes sense. In a nutshell, this is what PCA is all about: Finding the directions of maximum variance in high-dimensional data and project it onto a smaller dimensional subspace while retaining most of the information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Components Analysis\n",
    "\n",
    "Often, the desired goal is to reduce the dimensions of a **d**-dimensional dataset by projecting it onto a (**k**)-dimensional subspace (where **k** < **d**) in order to increase the computational efficiency while retaining most of the information. An important question is “what is the size of **k** that represents the data ‘well’?”\n",
    "\n",
    "Later, we will compute eigenvectors (the principal components) of a dataset and collect them in a projection matrix. Each of those eigenvectors is associated with an eigenvalue which can be interpreted as the “length” or “magnitude” of the corresponding eigenvector. If some eigenvalues have a significantly larger magnitude than others that the reduction of the dataset via PCA onto a smaller dimensional subspace by dropping the “less informative” eigenpairs is reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Explore the Iris Data Set\n",
    "\n",
    "[Original Data](https://archive.ics.uci.edu/ml/datasets/Iris). [Background Info](https://en.wikipedia.org/wiki/Iris_flower_data_set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Build a PCA Class\n",
    "\n",
    "General Steps for PCA ([walkthrough in R if you get stuck](http://alexhwoods.com/pca/)):\n",
    "1. Standardize the data.\n",
    "2. Obtain the Eigenvectors and Eigenvalues from the covariance matrix or correlation matrix, or perform Singular Vector Decomposition.\n",
    "3. Sort eigenvalues in descending order and choose the **k** eigenvectors that correspond to the **k** largest eigenvalues where **k** is the number of dimensions of the new feature subspace (**k ≤ d**).\n",
    "4. Construct the projection matrix **W** from the selected **k** eigenvectors.\n",
    "5. Transform the original dataset **X** via **W** to obtain a **k**-dimensional feature subspace **Y**.\n",
    "\n",
    "The class should be able to:\n",
    "- Calculate the principal components with an optional parameter\n",
    "- Project onto a 2-dimensional feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Try it out on the Iris Data Set\n",
    "\n",
    "1. Plot the individual explained variance vs. cumulative explained variance.\n",
    "2. Plot the Iris data set on the new 2-dimensional feature subspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Check via Scikit-Learn\n",
    "\n",
    "This exercise was purely academic. You will always use an optimized version of PCA in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
